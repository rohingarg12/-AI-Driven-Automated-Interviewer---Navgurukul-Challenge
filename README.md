# ğŸ“ AI-Driven Automated Interviewer for Project Presentations

An AI system that listens to a student presenting a project (screen share + speech) and conducts an adaptive interview based on content and responses.

![Tech Stack](https://img.shields.io/badge/Next.js-15-black?style=flat-square&logo=next.js)
![Groq](https://img.shields.io/badge/Groq-API-orange?style=flat-square)
![Llama](https://img.shields.io/badge/Llama-3.3%2070B-blue?style=flat-square)
![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)

## ğŸ¯ Features

- **Screen Capture & Analysis** - AI understands your code, slides, and diagrams 
- **Speech-to-Text** - Real-time transcription using Groq Whisper (whisper-large-v3-turbo)
- **Smart Question Generation** - Context-aware questions generated by Llama 3.3 70B
- **Text-to-Speech** - Natural voice output using Web Speech API
- **Comprehensive Evaluation** - Scoring on technical depth, clarity, originality, implementation, and communication
- **PDF Report** - Downloadable evaluation report

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ installed
- Groq API key (free at [console.groq.com](https://console.groq.com))

### Installation

```bash
# 1. Clone or copy the project
cd navgurukul-interviewer

# 2. Install dependencies
npm install

# 3. Set up environment
cp .env.example .env.local
# Edit .env.local and add your GROQ_API_KEY

# 4. Run the development server
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) in your browser.

## ğŸ“ Project Structure

```
navgurukul-interviewer/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ analyze/         # Screen analysis (Groq Vision)
â”‚   â”‚   â”œâ”€â”€ chat/            # Question generation (Llama 3.3)
â”‚   â”‚   â”œâ”€â”€ evaluate/        # Interview evaluation
â”‚   â”‚   â”œâ”€â”€ transcribe/      # Speech-to-text (Whisper)
â”‚   â”‚   â””â”€â”€ tts/             # Text-to-speech config
â”‚   â”œâ”€â”€ presentation/        # Phase 1: Screen share + recording
â”‚   â”œâ”€â”€ interview/           # Phase 2: Q&A session
â”‚   â”œâ”€â”€ evaluation/          # Phase 3: Results & report
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”œâ”€â”€ page.tsx             # Landing page
â”‚   â””â”€â”€ globals.css
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ui/                  # Button, Card, Badge, Progress
â”‚   â””â”€â”€ interview/           # ScreenCapture, VoiceRecorder, TTS
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ groq.ts              # Groq API client & prompts
â”‚   â”œâ”€â”€ store.ts             # Zustand state management
â”‚   â””â”€â”€ utils.ts             # Utility functions
â”œâ”€â”€ .env.example
â”œâ”€â”€ package.json
â”œâ”€â”€ tailwind.config.js
â””â”€â”€ README.md
```

## ğŸ”§ Tech Stack

| Component | Technology | Why |
|-----------|------------|-----|
| **Framework** | Next.js 15 + React 19 | Modern, fast, easy deploy |
| **Styling** | Tailwind CSS | Beautiful dark theme |
| **State** | Zustand | Simple, no boilerplate |
| **LLM** | Groq (Llama 3.3 70B) | 
| **Vision/OCR** | Groq (Llama 3.2 Vision) | Understands code context |
| **STT** | Groq Whisper | 95%+ accuracy, FREE |
| **TTS** | Web Speech API | Browser built-in, FREE |
| **PDF** | jsPDF | Client-side generation |

## ğŸ’° Cost: $0

Everything is **FREE**:
- Groq API: Free tier (very generous - 30 requests/minute)
- Web Speech API: Browser built-in
- Screen Capture: Browser built-in
- Hosting: Vercel free tier (optional)

## ğŸ® How It Works

### Phase 1: Presentation (3-5 minutes)
1. Click "Start Presentation"
2. Share your screen (code, slides, diagrams)
3. Explain your project verbally
4. AI captures screenshots every 5 seconds
5. AI transcribes your speech in real-time
6. Click "End & Start Interview"

### Phase 2: Interview (5-10 minutes)
1. AI generates 5 context-aware questions
2. AI speaks the question using TTS
3. You respond verbally
4. AI transcribes your response
5. Submit and move to next question

### Phase 3: Evaluation
1. AI analyzes all Q&A pairs
2. Scores on 5 criteria (1-10 each)
3. Provides detailed feedback
4. Download PDF report

## ğŸ“Š Evaluation Criteria

| Criteria | Description |
|----------|-------------|
| **Technical Depth** | Understanding of implementation details |
| **Clarity** | Ability to explain concepts clearly |
| **Originality** | Unique aspects and creative solutions |
| **Implementation** | Code quality and architecture |
| **Communication** | Overall presentation skills |

## ğŸ” Environment Variables

```env
# Required
GROQ_API_KEY=your_groq_api_key

# Optional
OPENAI_API_KEY=your_openai_key (for fallback)
```

## ğŸš€ Deployment

### Vercel (Recommended)

```bash
npm install -g vercel
vercel
```

### Docker (Optional)

```dockerfile
FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build
EXPOSE 3000
CMD ["npm", "start"]
```


## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing`)
5. Open a Pull Request

## ğŸ“„ License

MIT License - feel free to use for any purpose.

---

Built for **Navgurukul AI/ML Challenge** ğŸš€

Powered by Groq, Llama 3.3, Whisper & Web Speech API
